{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping para la biblia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_scraping_biblia(nombre_pasaje: str, num_paginas: str, path: str, cod_biblia: str, idioma: str):\n",
    "    \"\"\"\n",
    "    Hace un web scraping de la página bible.com a partir de un código de pasaje y un código de idioma y una carpeta para guardar el resultado\n",
    "\n",
    "    input:\n",
    "    - nombre_pasaje: Nombre del pasaje. Por ejemplo, Roma, Lucas, etc\n",
    "    - num_paginas: Número de páginas a revisar\n",
    "    - path: Ruta en donde guardar los resultados del web scraping\n",
    "    - cod_biblia: codigo de la biblia buscada\n",
    "    - idioma: Idioma puede ser español o wayuu\n",
    "    \"\"\"\n",
    "    if idioma == 'esp':\n",
    "        cod = '28'\n",
    "    else:\n",
    "        cod = '1584'\n",
    "    urls = [f\"https://www.bible.com/es/bible/{cod}/{nombre_pasaje}.{i}.{cod_biblia}\" for i in range(1,num_paginas+1)]\n",
    "    \n",
    "    for i in range(1,num_paginas+1):\n",
    "        # URL de la página web que deseas analizar\n",
    "        url = urls[i-1]\n",
    "\n",
    "        try:\n",
    "            # Realiza una solicitud GET para obtener el contenido de la página\n",
    "            response = requests.get(url)\n",
    "\n",
    "            # Verifica si la solicitud fue exitosa (código de respuesta 200)\n",
    "            if response.status_code == 200:\n",
    "                # Parsea el contenido HTML de la página con BeautifulSoup\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "                # Encuentra el elemento <div> con data-usfm=\"ACT.2\" y la clase \"ChapterContent_chapter__uvbXo\"\n",
    "                act = f\"{nombre_pasaje}.{i}\"\n",
    "                div_element = soup.find(\"div\", {\"data-usfm\": act, \"class\": \"ChapterContent_chapter__uvbXo\"})\n",
    "\n",
    "                # Verifica si se encontró el elemento\n",
    "                if div_element:\n",
    "                    # Obtiene el contenido dentro del elemento <div>\n",
    "                    contenido = div_element.get_text()\n",
    "                    contenido = contenido[len(str(i))+1:]\n",
    "\n",
    "                    with open(path + f'{nombre_pasaje} {i} - {idioma}.txt', 'w') as f:\n",
    "                        f.write(contenido)\n",
    "                else:\n",
    "                    print(\"No se encontró el elemento <div> con los atributos especificados.\")\n",
    "            else:\n",
    "                print(f\"No se pudo acceder a {url}. Código de respuesta: {response.status_code}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Se produjo un error al acceder a {url}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = [\n",
    "    ('MAT', 28, 'Mateo'),\n",
    "    ('MRK', 16, 'Marcos'),\n",
    "    ('LUK', 24, 'Lucas'),\n",
    "    ('JHN', 21, 'Juan'),\n",
    "    ('ACT', 28, 'Hechos de los apostoles'),\n",
    "    ('ROM', 16,'Roma'),\n",
    "    ('1CO', 16, 'Corintio'),\n",
    "    ('2CO', 13, 'Corintio2'),\n",
    "    ('GAL', 6, 'Galacia'),\n",
    "    ('EPH', 6, 'Efeso'),\n",
    "    ('PHP', 4, 'Filipos'),\n",
    "    ('COL', 4, 'Colosa'),\n",
    "    ('1TH', 5, 'Tesalonica'),\n",
    "    ('2TH', 3, '2Tesalonica'),\n",
    "    ('1TI', 6, 'Timoteo'),\n",
    "    ('2TI', 4, '2Timoteo'),\n",
    "    ('TIT', 3, 'Tito'),\n",
    "    ('PHM', 1, 'Filemon'),\n",
    "    ('HEB', 13, 'Hebreokana'),\n",
    "    ('JAS', 5, 'Santiago'),\n",
    "    ('1PE', 5, 'Pedro'),\n",
    "    ('2PE', 3, '2Pedro'),\n",
    "    ('1JN', 5, '1 Juan'),\n",
    "    ('2JN', 1, '2 Juan'),\n",
    "    ('3JN', 1, '3 Juan'),\n",
    "    ('JUD', 1, 'Judas'),\n",
    "    ('REV', 22, 'Apocalipsis')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nombp, nump, fol in lista:\n",
    "    web_scraping_biblia(nombre_pasaje = nombp, \n",
    "                        num_paginas = nump, \n",
    "                        path = f'../data/biblia/{fol}/', \n",
    "                        cod_biblia = 'GUC', \n",
    "                        idioma = 'wayuu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nombp, nump, fol in lista:\n",
    "    web_scraping_biblia(nombre_pasaje = nombp, \n",
    "                        num_paginas = nump, \n",
    "                        path = f'../data/biblia/{fol}/', \n",
    "                        cod_biblia = 'BLPH', \n",
    "                        idioma = 'esp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesar errores en español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "espaniol = glob('../data/biblia/*/* - esp.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ar in espaniol:\n",
    "    with open(ar, 'r') as f:\n",
    "        t = ' '.join(f.readlines())\n",
    "\n",
    "    # Quitamos saltos de línea\n",
    "    t = t.replace('\\n', ' ')\n",
    "\n",
    "    # Quitamos todo lo que está dentro de paréntesis (normalmente son pie de página o títulos)\n",
    "    t = re.sub(r'\\([^)]*\\)', \"\", t)\n",
    "\n",
    "    # Quitamos todo entre # y . que son pie de página\n",
    "    t = re.sub(r'#.*?\\.', '', t)\n",
    "\n",
    "    with open(ar, 'w') as f:\n",
    "        f.write(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ar in espaniol:\n",
    "    with open(ar, 'r') as f:\n",
    "        t = ' '.join(f.readlines())\n",
    "    if \"#\" in t:\n",
    "        print(f'No funcionó {ar}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ar in espaniol:\n",
    "    with open(ar, 'r') as f:\n",
    "        t = ' '.join(f.readlines())\n",
    "\n",
    "    t = re.sub(r'(\\d+)', r'\\n\\1', t)\n",
    "\n",
    "    with open(ar, 'w') as f:\n",
    "        f.write(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ar in espaniol:\n",
    "    with open(ar, 'r') as f:\n",
    "        t = ' '.join(f.readlines())\n",
    "\n",
    "    lines = t.split('\\n')\n",
    "    t = '\\n'.join([l for l in lines if len(l)>12])\n",
    "\n",
    "    with open(ar, 'w') as f:\n",
    "        f.write(t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesar más errores en wayuu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "wayuu = glob('../data/biblia/*/* - wayuu.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ar in wayuu:\n",
    "    with open(ar, 'r') as f:\n",
    "        t = ' '.join(f.readlines())\n",
    "\n",
    "    t = re.sub(r'(\\d+)', r'\\n\\1', t)\n",
    "\n",
    "    with open(ar, 'w') as f:\n",
    "        f.write(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeros_wayuu = {'1.\\n000': 'miirü',\n",
    "                 '2.\\n000': 'piama miirü',\n",
    "                 '4.\\n000': 'pienchi miirü',\n",
    "                 '5.\\n000': 'ja’rai miirü', \n",
    "                 '7.\\n000': 'akaraishi miirü',\n",
    "                 '12.\\n000': 'po’loo piamamüin miirü',\n",
    "                 '23.\\n000': 'piama shikii apünüinmüin miirü',\n",
    "                 '50.\\n000': 'ja’rai shikii miirü',\n",
    "                 '144.\\n000': 'po’loo shikii, pienchi shikii pienchimüin miirü',\n",
    "                 '10.\\n000': 'po’loo miirü',\n",
    "                 '20.\\n000': 'piama shikii miirü'}\n",
    "\n",
    "for ar in wayuu:\n",
    "    with open(ar, 'r') as f:\n",
    "        t = ''.join(f.readlines())\n",
    "\n",
    "    for k, v in numeros_wayuu.items():\n",
    "        t = t.replace(k,v)    \n",
    "\n",
    "    with open(ar, 'w') as f:\n",
    "        f.write(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_bid_ja",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
