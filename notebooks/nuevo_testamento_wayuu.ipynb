{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import pickle\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones útiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_text(text: str)-> str:\n",
    "    text = text.strip()\n",
    "    text = text.replace('(','').replace(')', '')\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    text = re.sub(r'\\s+[bcd]+\\s+', ' ', text)\n",
    "    text = re.sub(r' a ([A-Z])', r' \\1', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partir_versiculos(text: str) -> list:\n",
    "    versiculos = np.array([int(i) for i in re.findall(r'\\n(\\d+)', text)])\n",
    "    versiculos = range(1, np.max(versiculos)+1)\n",
    "\n",
    "    versiculos_idioma = []\n",
    "\n",
    "    for i in versiculos[:-1]:\n",
    "        if i ==  versiculos[-1]:\n",
    "            ver = '\\n '.join(text.split('\\n' + str(i))[1:])\n",
    "        else:\n",
    "            ver = '\\n '.join(text.split('\\n' + str(i))[1:])\n",
    "            ver = ver.split('\\n' + str(i+1))[0]\n",
    "    \n",
    "        ver = limpiar_text(ver)\n",
    "        versiculos_idioma.append(ver)\n",
    "    \n",
    "    return versiculos_idioma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_raw_text(text):\n",
    "    text = re.sub(r'\\n (\\d+)', r'\\n\\1', text)\n",
    "    return text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de los versículos que están juntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = [\n",
    "    ('MAT', 28, 'Mateo'),\n",
    "    ('MRK', 16, 'Marcos'),\n",
    "    ('LUK', 24, 'Lucas'),\n",
    "    ('JHN', 21, 'Juan'),\n",
    "    ('ACT', 28, 'Hechos de los apostoles'),\n",
    "    ('ROM', 16,'Roma'),\n",
    "    ('1CO', 16, 'Corintio'),\n",
    "    ('2CO', 13, 'Corintio2'),\n",
    "    ('GAL', 6, 'Galacia'),\n",
    "    ('EPH', 6, 'Efeso'),\n",
    "    ('PHP', 4, 'Filipos'),\n",
    "    ('COL', 4, 'Colosa'),\n",
    "    ('1TH', 5, 'Tesalonica'),\n",
    "    ('2TH', 3, '2Tesalonica'),\n",
    "    ('1TI', 6, 'Timoteo'),\n",
    "    ('2TI', 4, '2Timoteo'),\n",
    "    ('TIT', 3, 'Tito'),\n",
    "    ('PHM', 1, 'Filemon'),\n",
    "    ('HEB', 13, 'Hebreokana'),\n",
    "    ('JAS', 5, 'Santiago'),\n",
    "    ('1PE', 5, 'Pedro'),\n",
    "    ('2PE', 3, '2Pedro'),\n",
    "    ('1JN', 5, '1 Juan'),\n",
    "    ('2JN', 1, '2 Juan'),\n",
    "    ('3JN', 1, '3 Juan'),\n",
    "    ('JUD', 1, 'Judas'),\n",
    "    ('REV', 22, 'Apocalipsis')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAT 5\n",
      "MAT 7\n",
      "MAT 4\n",
      "MAT 8\n",
      "MAT 14\n",
      "MAT 11\n",
      "MAT 12\n",
      "MAT 13\n",
      "MAT 14\n",
      "MAT 4\n",
      "MAT 15\n",
      "MAT 22\n",
      "MAT 24\n",
      "MAT 5\n",
      "MAT 27\n",
      "MRK 3\n",
      "MRK 5\n",
      "MRK 4\n",
      "MRK 7\n",
      "MRK 12\n",
      "MRK 19\n",
      "MRK 13\n",
      "MRK 14\n",
      "MRK 52\n",
      "MRK 15\n",
      "MRK 41\n",
      "MRK 16\n",
      "LUK 1\n",
      "LUK 4\n",
      "LUK 9\n",
      "LUK 27\n",
      "LUK 33\n",
      "LUK 37\n",
      "LUK 40\n",
      "LUK 47\n",
      "LUK 52\n",
      "LUK 70\n",
      "LUK 72\n",
      "LUK 75\n",
      "LUK 2\n",
      "LUK 2\n",
      "LUK 5\n",
      "LUK 7\n",
      "LUK 31\n",
      "LUK 3\n",
      "LUK 4\n",
      "LUK 7\n",
      "LUK 11\n",
      "LUK 19\n",
      "LUK 22\n",
      "LUK 5\n",
      "LUK 24\n",
      "LUK 6\n",
      "LUK 8\n",
      "LUK 29\n",
      "LUK 42\n",
      "LUK 9\n",
      "LUK 31\n",
      "LUK 39\n",
      "LUK 10\n",
      "LUK 11\n",
      "LUK 10\n",
      "LUK 48\n",
      "LUK 12\n",
      "LUK 30\n",
      "LUK 36\n",
      "LUK 38\n",
      "LUK 48\n",
      "LUK 50\n",
      "LUK 13\n",
      "LUK 13\n",
      "LUK 25\n",
      "LUK 14\n",
      "LUK 16\n",
      "LUK 21\n",
      "LUK 17\n",
      "LUK 13\n",
      "LUK 16\n",
      "LUK 21\n",
      "LUK 18\n",
      "LUK 5\n",
      "LUK 19\n",
      "LUK 10\n",
      "LUK 21\n",
      "LUK 21\n",
      "LUK 23\n",
      "LUK 26\n",
      "LUK 22\n",
      "LUK 4\n",
      "LUK 6\n",
      "LUK 22\n",
      "LUK 30\n",
      "LUK 37\n",
      "LUK 23\n",
      "LUK 19\n",
      "LUK 45\n",
      "LUK 24\n",
      "LUK 10\n",
      "LUK 23\n",
      "JHN 2\n",
      "JHN 2\n",
      "JHN 3\n",
      "JHN 4\n",
      "JHN 2\n",
      "JHN 8\n",
      "JHN 45\n",
      "JHN 5\n",
      "JHN 4\n",
      "JHN 38\n",
      "JHN 7\n",
      "JHN 10\n",
      "JHN 11\n",
      "JHN 12\n",
      "JHN 11\n",
      "JHN 16\n",
      "JHN 6\n",
      "ACT 1\n",
      "ACT 2\n",
      "ACT 5\n",
      "ROM 1\n",
      "ROM 7\n",
      "ROM 2\n",
      "ROM 15\n",
      "ROM 3\n",
      "ROM 14\n",
      "ROM 20\n",
      "ROM 22\n",
      "ROM 4\n",
      "ROM 5\n",
      "ROM 8\n",
      "ROM 15\n",
      "ROM 21\n",
      "ROM 5\n",
      "ROM 7\n",
      "ROM 3\n",
      "ROM 16\n",
      "ROM 18\n",
      "ROM 8\n",
      "ROM 25\n",
      "ROM 27\n",
      "ROM 9\n",
      "ROM 3\n",
      "ROM 9\n",
      "ROM 12\n",
      "ROM 18\n",
      "ROM 21\n",
      "ROM 28\n",
      "ROM 11\n",
      "ROM 6\n",
      "ROM 10\n",
      "ROM 15\n",
      "ROM 2\n",
      "ROM 19\n",
      "1CO 1\n",
      "1CO 2\n",
      "1CO 6\n",
      "1CO 16\n",
      "1CO 29\n",
      "1CO 2\n",
      "1CO 3\n",
      "1CO 9\n",
      "1CO 13\n",
      "1CO 17\n",
      "1CO 5\n",
      "1CO 5\n",
      "1CO 7\n",
      "1CO 4\n",
      "1CO 8\n",
      "1CO 9\n",
      "1CO 12\n",
      "1CO 18\n",
      "1CO 23\n",
      "1CO 10\n",
      "1CO 11\n",
      "1CO 14\n",
      "1CO 25\n",
      "1CO 31\n",
      "1CO 15\n",
      "1CO 2\n",
      "1CO 22\n",
      "1CO 26\n",
      "1CO 31\n",
      "1CO 43\n",
      "1CO 47\n",
      "1CO 49\n",
      "2CO 1\n",
      "2CO 14\n",
      "2CO 16\n",
      "2CO 19\n",
      "2CO 2\n",
      "2CO 3\n",
      "2CO 8\n",
      "2CO 5\n",
      "2CO 3\n",
      "2CO 6\n",
      "2CO 8\n",
      "2CO 2\n",
      "2CO 12\n",
      "GAL 1\n",
      "GAL 2\n",
      "GAL 16\n",
      "GAL 2\n",
      "GAL 2\n",
      "GAL 4\n",
      "GAL 12\n",
      "GAL 4\n",
      "GAL 20\n",
      "GAL 23\n",
      "EPH 1\n",
      "EPH 16\n",
      "EPH 2\n",
      "EPH 5\n",
      "EPH 9\n",
      "EPH 3\n",
      "EPH 15\n",
      "EPH 17\n",
      "EPH 19\n",
      "EPH 4\n",
      "EPH 23\n",
      "EPH 5\n",
      "EPH 24\n",
      "EPH 6\n",
      "EPH 3\n",
      "PHP 1\n",
      "PHP 2\n",
      "PHP 4\n",
      "COL 1\n",
      "COL 2\n",
      "COL 4\n",
      "1TH 1\n",
      "1TH 4\n",
      "1TH 5\n",
      "2TH 2\n",
      "1TI 2\n",
      "1TI 5\n",
      "1TI 6\n",
      "2TI 2\n",
      "2TI 3\n",
      "TIT 2\n",
      "TIT 4\n",
      "PHM 1\n",
      "HEB 4\n",
      "HEB 6\n",
      "HEB 3\n",
      "HEB 6\n",
      "HEB 14\n",
      "HEB 7\n",
      "HEB 10\n",
      "HEB 14\n",
      "HEB 19\n",
      "HEB 9\n",
      "HEB 10\n",
      "HEB 12\n",
      "HEB 13\n",
      "HEB 20\n",
      "HEB 13\n",
      "JAS 1\n",
      "JAS 8\n",
      "JAS 11\n",
      "JAS 2\n",
      "JAS 3\n",
      "JAS 4\n",
      "JAS 5\n",
      "JAS 6\n",
      "1PE 1\n",
      "1PE 2\n",
      "2PE 1\n",
      "2PE 14\n",
      "2PE 2\n",
      "2PE 3\n",
      "1JN 1\n",
      "1JN 3\n",
      "1JN 5\n",
      "1JN 8\n",
      "1JN 15\n",
      "3JN 1\n",
      "REV 4\n",
      "REV 6\n",
      "REV 7\n",
      "REV 8\n",
      "REV 12\n",
      "REV 14\n",
      "REV 21\n"
     ]
    }
   ],
   "source": [
    "for cod, num, folder in lista:\n",
    "    traduccion = []\n",
    "    for i in range(1,num+1):\n",
    "        path = f'../data/biblia/{folder}/'\n",
    "\n",
    "        with open(path + f'{cod} {i} - esp.txt', 'r') as f:\n",
    "            esp = ''.join(f.readlines())\n",
    "        with open(path + f'{cod} {i} - wayuu.txt', 'r') as f:\n",
    "            wayuu = ''.join(f.readlines())\n",
    "\n",
    "        # Buscamos los versículos que es Wayuu están pegados de la forma 1-5\n",
    "        # Esto quiere decir que deben juntar todos en un solo versículo (1)\n",
    "        # Y en el correspondiente de español se deben \n",
    "\n",
    "        patron = r'\\n(\\d+)-\\n(\\d+)'\n",
    "        coincidencias_wayuu = re.findall(patron, wayuu)\n",
    "\n",
    "        if coincidencias_wayuu:\n",
    "            for coincidencia in coincidencias_wayuu:\n",
    "                print(cod, i)\n",
    "                numero1, numero2 = coincidencia\n",
    "                # Reemplazar la coincidencia por el primer número\n",
    "                wayuu = wayuu.replace(f\"{numero1}-\\n{numero2}\", str(numero1), 1)\n",
    "\n",
    "                for i in range(int(numero1) + 1, int(numero2)+1):\n",
    "                    esp = esp.replace(str(i), \"\", 1)\n",
    "\n",
    "            with open(path + f'{cod} {i} - esp.txt', 'w') as f:\n",
    "                f.write(esp)\n",
    "            \n",
    "            with open(path + f'{cod} {i} - wayuu.txt', 'w') as f:\n",
    "                f.write(wayuu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revisar cap 6 de MAT 33 41\n",
      "Revisar cap 28 de MAT 19 47\n",
      "Revisar cap 5 de LUK 38 45\n",
      "Revisar cap 7 de LUK 499 49\n",
      "Revisar cap 19 de LUK 47 54\n",
      "Revisar cap 13 de JHN 37 44\n",
      "Revisar cap 21 de JHN 152 74\n",
      "Revisar cap 1 de ACT 119 63\n",
      "Revisar cap 5 de ACT 399 41\n",
      "Revisar cap 7 de ACT 399 59\n",
      "Revisar cap 13 de ACT 449 59\n",
      "Revisar cap 19 de ACT 40 39\n",
      "Revisar cap 23 de ACT 199 34\n",
      "Revisar cap 24 de ACT 26 29\n",
      "Revisar cap 27 de ACT 275 43\n",
      "Revisar cap 15 de 1CO 499 57\n",
      "Revisar cap 13 de 2CO 13 12\n",
      "Revisar cap 3 de GAL 429 28\n",
      "Revisar cap 1 de JUD 199 24\n",
      "Revisar cap 1 de REV 19 21\n",
      "Revisar cap 11 de REV 259 18\n",
      "Revisar cap 12 de REV 259 17\n",
      "Revisar cap 13 de REV 665 17\n",
      "Revisar cap 14 de REV 299 19\n",
      "Revisar cap 21 de REV 199 26\n",
      "Revisar cap 22 de REV 20 24\n"
     ]
    }
   ],
   "source": [
    "for cod, num, folder in lista:\n",
    "    traduccion = []\n",
    "    for i in range(1,num+1):\n",
    "        path = f'../data/biblia/{folder}/'\n",
    "\n",
    "        with open(path + f'{cod} {i} - esp.txt', 'r') as f:\n",
    "            esp = ''.join(f.readlines())\n",
    "        with open(path + f'{cod} {i} - wayuu.txt', 'r') as f:\n",
    "            wayuu = ''.join(f.readlines())\n",
    "\n",
    "        patron = r'\\n\\d+-\\n'\n",
    "        coincidencias = re.findall(patron, texto, re.MULTILINE)\n",
    "        \n",
    "        \n",
    "        wayuu = clean_raw_text(wayuu)\n",
    "        esp = clean_raw_text(esp)\n",
    "\n",
    "        wayuu = partir_versiculos(wayuu)\n",
    "        esp = partir_versiculos(esp)\n",
    "\n",
    "        if coincidencias_es is not None or coincidencias_way is not None:\n",
    "            print(f'Revisar cap {i} de {cod}. Hay coincidencias de n-m')\n",
    "\n",
    "        elif len(wayuu) == len(esp):\n",
    "            for w, e in zip(wayuu, esp): \n",
    "                traduccion.append({'wayuu': w, 'esp': e})\n",
    "        else:\n",
    "            print(f'Revisar cap {i} de {cod}',  len(wayuu), len(esp))\n",
    "\n",
    "        \n",
    "    \n",
    "    with open(path + 'results.pickle', 'wb') as f:\n",
    "        pickle.dump(traduccion, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_bid_ja",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
