{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import PyPDF2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from matplotlib import pyplot as plt\n",
    "from pdf2image import convert_from_path\n",
    "from unidecode import unidecode\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_text(text: str)-> str:\n",
    "    text = text.strip()\n",
    "    text = text.replace('(','').replace(')', '')\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    text = re.sub(r'\\s+[bcd]+\\s+', ' ', text)\n",
    "    text = re.sub(r' a ([A-Z])', r' \\1', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partir_versiculos(text: str) -> list:\n",
    "    versiculos = np.array([int(i) for i in re.findall(r'\\n(\\d+)', text)])\n",
    "    versiculos = range(1, np.max(versiculos)+1)\n",
    "\n",
    "    versiculos_idioma = []\n",
    "\n",
    "    for i in versiculos[:-1]:\n",
    "        if i ==  versiculos[-1]:\n",
    "            ver = '\\n '.join(text.split('\\n' + str(i))[1:])\n",
    "        else:\n",
    "            ver = '\\n '.join(text.split('\\n' + str(i))[1:])\n",
    "            ver = ver.split('\\n' + str(i+1))[0]\n",
    "    \n",
    "        ver = limpiar_text(ver)\n",
    "        versiculos_idioma.append(ver)\n",
    "    \n",
    "    return versiculos_idioma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_texto_crudo(text: str) -> list:\n",
    "    text = re.sub(r'(\\d+)', r'\\n\\1 ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_traducciones(dict_traducciones):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mateo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/biblia/Mateo/'\n",
    "traduccion = []\n",
    "\n",
    "\n",
    "for i in range(1,28):\n",
    "    with open(path + f'Mateo {i} - esp.txt', 'r') as f:\n",
    "        mateo_esp = ''.join(f.readlines())\n",
    "    with open(path + f'Mateo {i} - wayuu.txt', 'r') as f:\n",
    "        mateo_wayuu = ''.join(f.readlines())\n",
    "\n",
    "    mateo_wayuu = procesar_texto_crudo(mateo_wayuu)\n",
    "    mateo_esp = procesar_texto_crudo(mateo_esp)\n",
    "\n",
    "    mateo_wayuu = partir_versiculos(mateo_wayuu)\n",
    "    mateo_esp = partir_versiculos(mateo_esp)\n",
    "\n",
    "    if len(mateo_wayuu) == len(mateo_esp):\n",
    "        for w, e in zip(mateo_wayuu, mateo_esp): \n",
    "            traduccion.append({'wayuu': w, 'esp': e})\n",
    "    else:\n",
    "        print(f'Revisar cap {i}',  len(mateo_wayuu), len(mateo_esp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traduccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'resultado.pickle', 'wb') as f:\n",
    "    pickle.dump(traduccion, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marcos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/biblia/Marcos/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'EBOOK-MARCOS.txt', 'r') as f:\n",
    "    marcos_es = ''\n",
    "    for line in f.readlines():\n",
    "        if not 'EVANGELIO SEGÚN SAN MARCOS' in line:\n",
    "            marcos_es += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos y guardamos por capítulo\n",
    "for i in range(1,17):\n",
    "    if i == 16:\n",
    "        cap = marcos_es.split(f'MARCOS {i}')[1]\n",
    "    else: \n",
    "        cap = marcos_es.split(f'MARCOS {i}')[1]\n",
    "        cap = cap.split(f'MARCOS {i+1}')[0]\n",
    "    \n",
    "    cap = '\\n'.join(cap.split('\\n')[1:])\n",
    "    cap = re.sub(r'\\n(\\d+)\\n', r'', cap)\n",
    "    with open(path + f'Marcos {i} - esp.txt', 'w') as f:\n",
    "        f.write(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "traduccion = []\n",
    "\n",
    "for i in range(1,17):\n",
    "    with open(path + f'Marcos {i} - esp.txt', 'r') as f:\n",
    "        mateo_esp = ''.join(f.readlines())\n",
    "    with open(path + f'Marcos {i} - wayuu.txt', 'r') as f:\n",
    "        mateo_wayuu = ''.join(f.readlines())\n",
    "\n",
    "    mateo_wayuu = procesar_texto_crudo(mateo_wayuu)\n",
    "    mateo_esp = procesar_texto_crudo(mateo_esp)\n",
    "\n",
    "    mateo_wayuu = partir_versiculos(mateo_wayuu)\n",
    "    mateo_esp = partir_versiculos(mateo_esp)\n",
    "\n",
    "    if len(mateo_wayuu) == len(mateo_esp):\n",
    "        for w, e in zip(mateo_wayuu, mateo_esp): \n",
    "            traduccion.append({'wayuu': w, 'esp': e})\n",
    "    else:\n",
    "        print(f'Revisar cap {i}',  len(mateo_wayuu), len(mateo_esp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "662"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traduccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'resultado.pickle', 'wb') as f:\n",
    "    pickle.dump(traduccion, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lucas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/biblia/Lucas/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'EBOOK-LUCAS.txt', 'r') as f:\n",
    "    lucas_es = ''\n",
    "    for line in f.readlines():\n",
    "        if not 'EVANGELIO SEGÚN SAN LUCAS' in line:\n",
    "            lucas_es += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos y guardamos por capítulo\n",
    "for i in range(1,25):\n",
    "    if i == 24:\n",
    "        cap = lucas_es.split(f'LUCAS {i}')[1]\n",
    "    else: \n",
    "        cap = lucas_es.split(f'LUCAS {i}')[1]\n",
    "        cap = cap.split(f'LUCAS {i+1}')[0]\n",
    "    \n",
    "    cap = '\\n'.join(cap.split('\\n')[1:])\n",
    "    cap = re.sub(r'\\n(\\d+)\\n', r'', cap)\n",
    "    cap = re.sub(r'\\(([\\d, -]+)\\)', '', cap)\n",
    "\n",
    "    with open(path + f'Lucas {i} - esp.txt', 'w') as f:\n",
    "        f.write(cap)\n",
    "    \n",
    "    if not os.path.exists(path + f'Lucas {i} - wayuu.txt'):\n",
    "\n",
    "        with open(path + f'Lucas {i} - wayuu.txt', \"w\"):\n",
    "            pass \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "traduccion = []\n",
    "\n",
    "for i in range(1,17):\n",
    "    with open(path + f'Lucas {i} - esp.txt', 'r') as f:\n",
    "        mateo_esp = ''.join(f.readlines())\n",
    "    with open(path + f'Lucas {i} - wayuu.txt', 'r') as f:\n",
    "        mateo_wayuu = ''.join(f.readlines())\n",
    "\n",
    "    mateo_wayuu = procesar_texto_crudo(mateo_wayuu)\n",
    "    mateo_esp = procesar_texto_crudo(mateo_esp)\n",
    "\n",
    "    mateo_wayuu = partir_versiculos(mateo_wayuu)\n",
    "    mateo_esp = partir_versiculos(mateo_esp)\n",
    "\n",
    "    if len(mateo_wayuu) == len(mateo_esp):\n",
    "        for w, e in zip(mateo_wayuu, mateo_esp): \n",
    "            traduccion.append({'wayuu': w, 'esp': e})\n",
    "    else:\n",
    "        print(f'Revisar cap {i}',  len(mateo_wayuu), len(mateo_esp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "742"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traduccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'resultado.pickle', 'wb') as f:\n",
    "    pickle.dump(traduccion, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Juan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/biblia/Juan/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'EBOOK-JUAN.txt', 'r') as f:\n",
    "    juan_es = ''\n",
    "    for line in f.readlines():\n",
    "        if not 'EVANGELIO SEGÚN SAN JUAN' in line:\n",
    "            juan_es += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos y guardamos por capítulo\n",
    "for i in range(1,22):\n",
    "    if i == 21:\n",
    "        cap = juan_es.split(f'JUAN {i}')[1]\n",
    "    else: \n",
    "        cap = juan_es.split(f'JUAN {i}')[1]\n",
    "        cap = cap.split(f'JUAN {i+1}')[0]\n",
    "    \n",
    "    cap = '\\n'.join(cap.split('\\n')[1:])\n",
    "    cap = re.sub(r'\\n(\\d+)\\n', r'', cap)\n",
    "    cap = re.sub(r'\\(([\\d, -]+)\\)', '', cap)\n",
    "\n",
    "    with open(path + f'Juan {i} - esp.txt', 'w') as f:\n",
    "        f.write(cap)\n",
    "    \n",
    "    if not os.path.exists(path + f'Juan {i} - wayuu.txt'):\n",
    "\n",
    "        with open(path + f'Juan {i} - wayuu.txt', \"w\"):\n",
    "            pass \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "traduccion = []\n",
    "\n",
    "for i in range(1,17):\n",
    "    with open(path + f'Juan {i} - esp.txt', 'r') as f:\n",
    "        juan_esp = ''.join(f.readlines())\n",
    "    with open(path + f'Juan {i} - wayuu.txt', 'r') as f:\n",
    "        juan_wayuu = ''.join(f.readlines())\n",
    "\n",
    "    juan_wayuu = procesar_texto_crudo(juan_wayuu)\n",
    "    juan_esp = procesar_texto_crudo(juan_esp)\n",
    "\n",
    "    juan_wayuu = partir_versiculos(juan_wayuu)\n",
    "    juan_esp = partir_versiculos(juan_esp)\n",
    "\n",
    "    if len(juan_wayuu) == len(juan_esp):\n",
    "        for w, e in zip(juan_wayuu, juan_esp): \n",
    "            traduccion.append({'wayuu': w, 'esp': e})\n",
    "    else:\n",
    "        print(f'Revisar cap {i}',  len(juan_wayuu), len(juan_esp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "699"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traduccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'resultado.pickle', 'wb') as f:\n",
    "    pickle.dump(traduccion, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hechos de los apóstoles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/biblia/Hechos de los apostoles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'EBOOK-HECHOS DE LOS APÓSTOLES.txt', 'r') as f:\n",
    "    ap_es = ''\n",
    "    for line in f.readlines():\n",
    "        if not 'SAN LUCAS HECHOS DE LOS APÓSTOLES' in line:\n",
    "            ap_es += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR EN  21\n"
     ]
    }
   ],
   "source": [
    "# Separamos y guardamos por capítulo\n",
    "for i in range(1,29):\n",
    "    try:\n",
    "        if i == 28:\n",
    "            cap = ap_es.split(f'HECHOS {i}')[1]\n",
    "        else: \n",
    "            cap = ap_es.split(f'HECHOS {i}')[1]\n",
    "            cap = cap.split(f'HECHOS {i+1}')[0]\n",
    "        \n",
    "        cap = '\\n'.join(cap.split('\\n')[1:])\n",
    "        cap = re.sub(r'\\n(\\d+)\\n', r'', cap)\n",
    "        cap = re.sub(r'\\(([\\d, -]+)\\)', '', cap)\n",
    "\n",
    "        with open(path + f'HDLA {i} - esp.txt', 'w') as f:\n",
    "            f.write(cap)\n",
    "        \n",
    "        if not os.path.exists(path + f'HDLA {i} - wayuu.txt'):\n",
    "\n",
    "            with open(path + f'HDLA {i} - wayuu.txt', \"w\"):\n",
    "                pass \n",
    "    except:\n",
    "        print('ERROR EN ', i)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "traduccion = []\n",
    "\n",
    "for i in range(1,17):\n",
    "    with open(path + f'HDLA {i} - esp.txt', 'r') as f:\n",
    "        juan_esp = ''.join(f.readlines())\n",
    "    with open(path + f'HDLA {i} - wayuu.txt', 'r') as f:\n",
    "        juan_wayuu = ''.join(f.readlines())\n",
    "\n",
    "    juan_wayuu = procesar_texto_crudo(juan_wayuu)\n",
    "    juan_esp = procesar_texto_crudo(juan_esp)\n",
    "\n",
    "    juan_wayuu = partir_versiculos(juan_wayuu)\n",
    "    juan_esp = partir_versiculos(juan_esp)\n",
    "\n",
    "    if len(juan_wayuu) == len(juan_esp):\n",
    "        for w, e in zip(juan_wayuu, juan_esp): \n",
    "            traduccion.append({'wayuu': w, 'esp': e})\n",
    "    else:\n",
    "        print(f'Revisar cap {i}',  len(juan_wayuu), len(juan_esp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "584"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traduccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'resultado.pickle', 'wb') as f:\n",
    "    pickle.dump(traduccion, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/biblia/Roma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'CARTA A LOS ROMANOS.txt', 'r') as f:\n",
    "    ap_es = ''\n",
    "    for line in f.readlines():\n",
    "        if not 'CARTA A LOS ROMANOS' in line:\n",
    "            ap_es += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos y guardamos por capítulo\n",
    "for i in range(1,17):\n",
    "    try:\n",
    "        if i == 16:\n",
    "            cap = ap_es.split(f'ROMANOS {i}')[1]\n",
    "        else: \n",
    "            cap = ap_es.split(f'ROMANOS {i}')[1]\n",
    "            cap = cap.split(f'ROMANOS {i+1}')[0]\n",
    "        \n",
    "        cap = '\\n'.join(cap.split('\\n')[1:])\n",
    "        cap = re.sub(r'\\n(\\d+)\\n', r'', cap)\n",
    "        cap = re.sub(r'\\(([\\d, -§]+)\\)', '', cap)\n",
    "\n",
    "        with open(path + f'Roma {i} - esp.txt', 'w') as f:\n",
    "            f.write(cap)\n",
    "    except:\n",
    "        print('ERROR EN ', i)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "traduccion = []\n",
    "\n",
    "for i in range(1,17):\n",
    "    with open(path + f'Roma {i} - esp.txt', 'r') as f:\n",
    "        esp = ''.join(f.readlines())\n",
    "    with open(path + f'Roma {i} - wayuu.txt', 'r') as f:\n",
    "        wayuu = ''.join(f.readlines())\n",
    "\n",
    "    # Encontrar los pasajes que están pegados\n",
    "    patron = r'(\\d+)-(\\d+)'\n",
    "    coincidencias = re.findall(patron, wayuu)\n",
    "    for coincidencia in coincidencias:\n",
    "        numero1, numero2 = coincidencia\n",
    "        # Reemplazar la coincidencia por el primer número\n",
    "        wayuu = wayuu.replace(f\"{numero1}-{numero2}\", numero1)\n",
    "\n",
    "        esp = esp.replace(numero2, \"\", 1)\n",
    "\n",
    "\n",
    "    wayuu = procesar_texto_crudo(wayuu)\n",
    "    esp = procesar_texto_crudo(esp)\n",
    "\n",
    "    wayuu = partir_versiculos(wayuu)\n",
    "    esp = partir_versiculos(esp)\n",
    "\n",
    "    if len(wayuu) == len(esp):\n",
    "        for w, e in zip(wayuu, esp): \n",
    "            traduccion.append({'wayuu': w, 'esp': e})\n",
    "    else:\n",
    "        print(f'Revisar cap {i}',  len(wayuu), len(esp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traduccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'resultado.pickle', 'wb') as f:\n",
    "    pickle.dump(traduccion, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corintios 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/biblia/Corintio/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'EBOOK-PRIMERA CARTA A LOS CORINTIOS.txt', 'r') as f:\n",
    "    ap_es = ''\n",
    "    for line in f.readlines():\n",
    "        if not 'PRIMERA CARTA A LOS CORINTIO' in line:\n",
    "            ap_es += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos y guardamos por capítulo\n",
    "for i in range(1,17):\n",
    "    try:\n",
    "        if i == 16:\n",
    "            cap = ap_es.split(f'CORINTIOS1 {i}')[1]\n",
    "        else: \n",
    "            cap = ap_es.split(f'CORINTIOS1 {i}')[1]\n",
    "            cap = cap.split(f'CORINTIOS1 {i+1}')[0]\n",
    "        \n",
    "        cap = '\\n'.join(cap.split('\\n')[1:])\n",
    "        cap = re.sub(r'\\n(\\d+)\\n', r'', cap)\n",
    "        cap = re.sub(r'\\(([\\d, -§]+)\\)', '', cap)\n",
    "\n",
    "        with open(path + f'1CO {i} - esp.txt', 'w') as f:\n",
    "            f.write(cap)\n",
    "    except:\n",
    "        print('ERROR EN ', i)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "traduccion = []\n",
    "\n",
    "for i in range(1,17):\n",
    "    with open(path + f'1CO {i} - esp.txt', 'r') as f:\n",
    "        esp = ''.join(f.readlines())\n",
    "    with open(path + f'1CO {i} - wayuu.txt', 'r') as f:\n",
    "        wayuu = ''.join(f.readlines())\n",
    "\n",
    "    # Encontrar los pasajes que están pegados\n",
    "    patron = r'(\\d+)-(\\d+)'\n",
    "    coincidencias = re.findall(patron, wayuu)\n",
    "    for coincidencia in coincidencias:\n",
    "        numero1, numero2 = coincidencia\n",
    "        # Reemplazar la coincidencia por el primer número\n",
    "        wayuu = wayuu.replace(f\"{numero1}-{numero2}\", str(numero1), 1)\n",
    "\n",
    "        for i in range(int(numero1) + 1, int(numero2)+1):\n",
    "            esp = esp.replace(str(i), \"\", 1)\n",
    "\n",
    "    wayuu = procesar_texto_crudo(wayuu)\n",
    "    esp = procesar_texto_crudo(esp)\n",
    "\n",
    "    wayuu = partir_versiculos(wayuu)\n",
    "    esp = partir_versiculos(esp)\n",
    "\n",
    "    if len(wayuu) == len(esp):\n",
    "        for w, e in zip(wayuu, esp): \n",
    "            traduccion.append({'wayuu': w, 'esp': e})\n",
    "    else:\n",
    "        print(f'Revisar cap {i}',  len(wayuu), len(esp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traduccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'resultado.pickle', 'wb') as f:\n",
    "    pickle.dump(traduccion, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corintios 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/biblia/Corintio2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'EBOOK-SEGUNDA CARTA A LOS CORINTIOS.txt', 'r') as f:\n",
    "    ap_es = ''\n",
    "    for line in f.readlines():\n",
    "        if not 'SEGUNDA CARTA A LOS CORINTIO' in line:\n",
    "            ap_es += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos y guardamos por capítulo\n",
    "for i in range(1,14):\n",
    "    try:\n",
    "        if i == 13:\n",
    "            cap = ap_es.split(f'CORINTIOS2 {i}')[1]\n",
    "        else: \n",
    "            cap = ap_es.split(f'CORINTIOS2 {i}')[1]\n",
    "            cap = cap.split(f'CORINTIOS2 {i+1}')[0]\n",
    "        \n",
    "        cap = '\\n'.join(cap.split('\\n')[1:])\n",
    "        cap = re.sub(r'\\n(\\d+)\\n', r'', cap)\n",
    "        cap = re.sub(r'\\(([\\d, -§]+)\\)', '', cap)\n",
    "\n",
    "        with open(path + f'2CO {i} - esp.txt', 'w') as f:\n",
    "            f.write(cap)\n",
    "    except:\n",
    "        print('ERROR EN ', i)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "traduccion = []\n",
    "\n",
    "for i in range(1,14):\n",
    "    with open(path + f'2CO {i} - esp.txt', 'r') as f:\n",
    "        esp = ''.join(f.readlines())\n",
    "    with open(path + f'2CO {i} - wayuu.txt', 'r') as f:\n",
    "        wayuu = ''.join(f.readlines())\n",
    "\n",
    "    # Encontrar los pasajes que están pegados\n",
    "    patron = r'(\\d+)-(\\d+)'\n",
    "    coincidencias = re.findall(patron, wayuu)\n",
    "    for coincidencia in coincidencias:\n",
    "        numero1, numero2 = coincidencia\n",
    "        # Reemplazar la coincidencia por el primer número\n",
    "        wayuu = wayuu.replace(f\"{numero1}-{numero2}\", str(numero1), 1)\n",
    "\n",
    "        for i in range(int(numero1) + 1, int(numero2)+1):\n",
    "            esp = esp.replace(str(i), \"\", 1)\n",
    "\n",
    "    wayuu = procesar_texto_crudo(wayuu)\n",
    "    esp = procesar_texto_crudo(esp)\n",
    "\n",
    "    wayuu = partir_versiculos(wayuu)\n",
    "    esp = partir_versiculos(esp)\n",
    "\n",
    "    if len(wayuu) == len(esp):\n",
    "        for w, e in zip(wayuu, esp): \n",
    "            traduccion.append({'wayuu': w, 'esp': e})\n",
    "    else:\n",
    "        print(f'Revisar cap {i}',  len(wayuu), len(esp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traduccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + 'resultado.pickle', 'wb') as f:\n",
    "    pickle.dump(traduccion, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galacia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_bid_ja",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
